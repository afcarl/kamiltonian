@inproceedings{sejdinovic_kernel_2014,
abstract = {A Kernel Adaptive Metropolis-Hastings algorithm is introduced, for the purpose of sampling from a target distribution with strongly nonlinear support. The algorithm embeds the trajectory of the Markov chain into a reproducing kernel Hilbert space (\{RKHS)\}, such that the feature space covariance of the samples informs the choice of proposal. The procedure is computationally efficient and straightforward to implement, since the \{RKHS\} moves can be integrated out analytically: our proposal distribution in the original space is a normal distribution whose mean and covariance depend on where the current sample lies in the support of the target distribution, and adapts to its local covariance structure. Furthermore, the procedure requires neither gradients nor any other higher order information about the target, making it particularly attractive for contexts such as Pseudo-Marginal \{MCMC.\} Kernel Adaptive Metropolis-Hastings outperforms competing fixed and adaptive samplers on multivariate, highly nonlinear target distributions, arising in both real-world and synthetic examples. Code may be downloaded at https://github.com/karlnapf/kameleon-mcmc},
author = {Sejdinovic, Dino and Strathmann, Heiko and Garcia, Maria Lomeli and Andrieu, Christophe and Gretton, Arthur},
booktitle = {International Conference of Machine Learning},
file = {:home/heiko/.zotero/zotero/oj1ghcpf.default/zotero/storage/9VWSHAFJ/Sejdinovic et al. - 2013 - Kernel Adaptive Metropolis-Hastings.pdf:pdf;:home/heiko/.zotero/zotero/oj1ghcpf.default/zotero/storage/5W26764T/1307.html:html},
keywords = {Computer Science - Learning,Statistics - Machine Learning},
title = {{Kernel Adaptive Metropolis-Hastings}},
year = {2014}
}
@article{Girolami2011,
author = {Girolami, Mark and Calderhead, Ben},
doi = {10.1111/j.1467-9868.2010.00765.x},
file = {:home/heiko/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Girolami, Calderhead - 2011 - Riemann manifold Langevin and Hamiltonian Monte Carlo methods.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {bayesian inference,geometry in statistics,hamiltonian monte carlo methods,langevin diffusion,markov chain monte carlo,methods,riemann manifolds},
month = mar,
number = {2},
pages = {123--214},
title = {{Riemann manifold Langevin and Hamiltonian Monte Carlo methods}},
volume = {73},
year = {2011}
}
@article{Andrieu2009,
author = {Andrieu, Christophe and Roberts, Gareth O.},
doi = {10.1214/07-AOS574},
file = {:home/heiko/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrieu, Roberts - 2009 - The pseudo-marginal approach for efficient Monte Carlo computations.pdf:pdf},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {and phrases,auxiliary variable,convergence,marginal,markov chain monte carlo},
month = apr,
number = {2},
pages = {697--725},
title = {{The pseudo-marginal approach for efficient Monte Carlo computations}},
volume = {37},
year = {2009}
}
@article{Neal2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1206.1901v1},
author = {Neal, RM},
eprint = {arXiv:1206.1901v1},
file = {:home/heiko/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neal - 2010 - MCMC using Hamiltonian dynamics.pdf:pdf},
journal = {Handbook of Markov Chain Monte Carlo},
title = {{MCMC using Hamiltonian dynamics}},
year = {2010}
}
@inproceedings{Rahimi2007,
abstract = {To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. Our randomized features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user specified shift-invariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classification and regression tasks linear machine learning algorithms that use these features outperform state-of-the-art large-scale kernel machines.},
author = {Rahimi, Ali and Recht, Ben},
booktitle = {Advances in Neural Information Processing Systems},
doi = {10.1.1.145.8736},
file = {:home/heiko/Downloads/07.rah.rec.nips.pdf:pdf},
isbn = {160560352X},
number = {1},
title = {{Random features for large-scale kernel machines}},
year = {2007}
}
